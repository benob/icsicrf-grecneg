#summary The icsi-crf system at grec'09
#labels Featured,Phase-Deploy

This page documents the system for the GREC-NEG 2009 evaluation campaign.

= Summary =

This is a system for entity reference expression generation for the Main
Subject References (MSR) and Named Entity Generation (NEG) tasks of the
Generation of References in Context (GREC) 2009 challenge.

http://www.nltg.brighton.ac.uk/research/genchal09/grec/

Our system generates the whole set of attributes of the referential expressions
(REFEX tag) and refines them using the text of the expression for person
entities. It relies on a Conditional Random Fields classifier (CRF) for
predicting the attributes.

The official results for [http://www.nltg.brighton.ac.uk/home/Anja.Belz/Publications/grec-msr-report-FINAL.pdf MSR] and [http://www.nltg.brighton.ac.uk/home/Anja.Belz/Publications/grec-neg-report-FINAL.pdf NEG] show that the system did very well for persons and less well for other classes (which we did not refine). On the NEG task, it even _outperformed_ humans on manual fluency evaluation. The system is briefly described in [http://www.aclweb.org/anthology/W/W09/W09-2818.pdf this paper].

===Requirements:===

  * CRF++ from http://crfpp.sourceforge.net/
  * python 2.5 with lxml (http://codespeak.net/lxml/)

===Scripts:===

  * `grec_data_to_crf_input.py`       convert grec training/test data to CRF++ format
  * `filter_crf_features.pl`          filter out unknown features marked with a question mark
  * `generate_crf_template.pl`        generate a template for CRF++
  * `crf_output_to_grec_output.py`    generate MSR/NEG output from CRF++ output


===Typical usage:===

{{{
python grec_data_to_crf_input.py GREC-MSR-09/Training-Data/train/*/*.xml | filter_crf_features.pl > grec_msr.train
python grec_data_to_crf_input.py GREC-MSR-09/Training-Data/dev/*/*.xml | filter_crf_features.pl > grec_msr.dev
perl generate_crf_template.pl `head -1 grec_msr.train | awk '{print NF}'` > grec_msr.template
crf_learn -c 1 -t -f 5 grec_msr.template grec_msr.train grec_msr.model
crf_test -v 2 -m grec_msr.model grec_msr.dev | python crf_output_to_grec_output.py
}}}

The results are generated in the `./output/` subdirectory

===Notes:===

`filter_crf_features.pl` replaces "?" by @num@ where this value is unique to the
training data so that crf_learn ignores it, thanks to the -f 5 option.

The first column of the CRF files contains the filename (hex-encoded to get rid
of character-encoding issues) and a unique id for the reference begin treated.
`generate_crf_template.pl` takes as first argument the number of columns for
which to generate templates, including the reference id column and the class
column.

`crf_output_to_grec_output.py` assumes that crf_test is called with the -v 2
options which generates posterior probabilities for all the classes. The output
directory is hard-coded as ./output/.

===Results on the dev set, with geval 2.1:===

  * NEG (crf_learn parameter -c = 0.07):

{{{
total pairs                   : 907
reg08 type matches            : 750
reg08 type accuracy           : 0.826901874310915
reg08 type precision          : 0.830490405117271
reg08 type recall             : 0.830490405117271
string matches                : 713
string accuracy               : 0.786108048511577
mean edit distance            : 0.532524807056229
mean normalised edit distance : 0.197413813676217
BLEU 1 score                  : 0.8118
BLEU 2 score                  : 0.8274
BLEU 3 score                  : 0.8297
BLEU 4 score                  : 0.8246
}}}

  * MSR (-c = 1):

{{{
total pairs                   : 656
reg08 type matches            : 495
reg08 type accuracy           : 0.754573170731707
reg08 type precision          : 0.754573170731707
reg08 type recall             : 0.754573170731707
string matches                : 443
string accuracy               : 0.67530487804878
mean edit distance            : 0.852134146341463
mean normalised edit distance : 0.279471544715447
BLEU 1 score                  : 0.6862
BLEU 2 score                  : 0.6004
BLEU 3 score                  : 0.5602
BLEU 4 score                  : 0.5345
}}}
===Citation:===

If you use this project to publish a paper, please cite:
{{{
@inproceedings{favre2009igr,
  author={Benoit Favre and Bernd Bonhet},
  title={{ICSI-CRF: The Generation of References to the Main Subject and Named Entities Using Conditional Random Fields}},
  booktitle={ACL-IJCNLP},
  year={2009}
}
}}}